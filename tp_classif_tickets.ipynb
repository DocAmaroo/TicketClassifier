{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI916 - IA GL | Dev. Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtudiant sur le projet\n",
    "\n",
    "| üéì NOM Pr√©nom | üìß Email | üè∑Ô∏è N¬∞ √âtudiant |\n",
    "| --- | --- | --- | \n",
    "**CANTA** Thomas | thomas.canta@etu.umontpellier.fr | 21607288\n",
    "**FONTAINE** Quentin | quentin.fontaine02@etu.umontpellier.fr | 21611404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from eli5.lime import TextExplainer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset\n",
    "\n",
    "Fonction permettant l'ouverture d'un jeu de ticket sauvegard√© au format json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(json_path):\n",
    "    raw_data = []\n",
    "    with codecs.open(json_path, \"r\", \"utf-8\") as fin:\n",
    "        raw_data += json.load(fin)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de multiplication des titres des tickets\n",
    "\n",
    "Multiplication du titre des tickets par le facteur donn√© en param√®tre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_title(dataset, factor):\n",
    "    for ticket in dataset:\n",
    "        for i in range(1,factor):\n",
    "            ticket[\"title\"] += \" \" + ticket[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de binarisation des labels\n",
    "\n",
    "Permet de convertir les labels \"NBUG\" et \"BUG\" en une information binaire 0 ou 1\n",
    "* 0 = NBUG\n",
    "* 1 = BUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization_labels(labels):\n",
    "    return np.ravel(label_binarize(labels, classes=[\"NBUG\",\"BUG\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de r√©cup√©ration du corpus et des √©tiquettes\n",
    "\n",
    "Cette fonction retourne deux tableaux :\n",
    "* Le premier est un tableau contenant les informations textuelles des tickets (pour chaque ticket, le title est concat√©n√© au body)\n",
    "* Le second tableau contient les labels textuelles associ√©es √† chacun des tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_labels(raw_data):\n",
    "# Corpus building.\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    n_bug = 0\n",
    "    for n_file in raw_data:\n",
    "        corpus.append(n_file[\"title\"] + \" \" + n_file[\"body\"])\n",
    "        labels.append(n_file[\"label\"])\n",
    "        if n_file[\"label\"] == \"BUG\":\n",
    "            n_bug += 1\n",
    "    print(f\"{n_bug} BUG / {len(labels)} \\n\")\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'√©valuation d'un classifieur avec un train/test split\n",
    "\n",
    "Cette fonction permet l'√©valuation d'un classifieur sur la base d'une division du jeu de donn√©es en 2 parties :\n",
    "* une partie d√©di√©e √† l'entra√Ænement (partie dite _train_)\n",
    "* une partie d√©di√©e au test du classifieur (partie dite _test_)\n",
    "Ici 77% des donn√©es du dataset sont destin√©es √† l'entra√Ænement et 33% au test du classifieur. \n",
    "La fonction calcule les mesures F1, rappel et pr√©cision. Elle dispose de 4 param√®tres :\n",
    "* X : le corpus complet vectoris√©\n",
    "* binarized_labels : la liste des labels binaris√©s\n",
    "* clf : le classifieur √† √©valuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scoring_train_test_split(X,binarized_labels, clf, test_size=33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='f1')\n",
    "    print(\"--- Start training ---\",flush=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"--- %s seconds for training ---\" % (time.time() - start_time),flush=True)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    print(\"F1 score train/test: %0.3f\" % f1)\n",
    "    print(\"Recall score train/test: %0.3f\" % recall)\n",
    "    print(\"Precision score train/test: %0.3f\" % precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de vectorisation et de calcul des features les plus repr√©sentatives\n",
    "Cette fonction prend 4 param√®tres en entr√©e : \n",
    "* corpus : tableau d'√©l√©ments textuels extraits avec la fonction <code>get_corpus_labels</code>\n",
    "* labels : tableau de labels binaris√©s avec la fonction <code>binarization_labels</code>\n",
    "* vectorizer : objet vectorizer pour transformer le corpus \n",
    "* k_best : nombre de features repr√©sentatives du corpus √† s√©lectionner √† l'aide du chi-deux\n",
    "* print_feature_names : afficher ou non les features s√©lectionn√©es par le chi2\n",
    "\n",
    "\n",
    "Vous allez devoir compl√©ter la fonction <code>feature_computing</code>, pour cela :\n",
    "1. Utilisez le vectorizer pass√© en param√®tre afin de transformer les informations textuelles en informatiques math√©matiques (vecteurs) utilisables par des classifieurs. Ces vecteurs sont cr√©√©s √† l'aide de la m√©thode _Term Frequency-Inverse Document Frequency_ ([wiki TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF)) Pour cela r√©f√©rez vous √† la fonction <code>fit_transform</code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform)). Vous affecterez le retour de <code>fit_transform</code> √† une variable nomm√©e <code>X</code>. \n",
    "2. La seconde √©tape consiste √† s√©lectionner les features les plus repr√©sentatives du corpus. Un moyen de faire cela est d'utiliser la m√©thode du Chi-deux. La m√©thode du chi deux va mesurer la d√©pendance entre une feature donn√©e et la classe (BUG ou NBUG) et ainsi vous permettre de s√©lectionner <code>k</code> features repr√©sentatives du corpus. Pour faire cela vous devez cr√©er un objet <code>SelectKBest</code> que vous affecterez √† la variable <code>ch2</code>. Vous pouvez vous inspirer de l'exemple donn√© dans la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest%20fit_transform).\n",
    "3. Utiliser la m√©thode <code>fit_transform</code> avec en param√®tres <code>X</code> et les <code>labels</code>. Affectez le retour de cette m√©thode √† la variable <code>X</code> \n",
    "\n",
    "Si vous souhaitez visualiser les features s√©lectionn√©es par le Chi2 vous pouvez passer la variable <code>print_feature_names</code> √† True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_computing(corpus, binarized_labels, vectorizer, k_best=30000, print_feature_names=False):\n",
    "    # TF-IDF.\n",
    "    start_time = time.time()\n",
    "    print(\"--- Start feature computing ---\")\n",
    "    \n",
    "    #Placer ici la ligne permettant de vectoriser le corpus avec fit_transform\n",
    "    X = vectorizer.fit_transform(corpus, binarized_labels)\n",
    "    print(f\"\\t{X.shape[1]} features.\")\n",
    "\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % k_best)\n",
    "    #Placer ici le code pour extraire les features\n",
    "    ch2 = SelectKBest(chi2, k=k_best)\n",
    "    X = ch2.fit_transform(X, binarized_labels)\n",
    "\n",
    "    if print_feature_names:  # keep selected feature names.\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "        feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "        print(feature_names)\n",
    "    \n",
    "    print(\"--- %s seconds for feature computing ---\" % (time.time() - start_time))\n",
    "    return X, vectorizer, ch2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de recherche d'un classifieur optimis√© \n",
    "\n",
    "Dans cette fonction nous allons utiliser un algorithme nomm√© Grid-Search (type brute-force) permettant d'optimiser les param√®tres d'un ou plusieurs classifieur(s) puis d'en comparer les performances. Nous allons comparer 5 types de classifieurs disponibles dans Scikit Learn :\n",
    "* Software Vector Machine (SVC ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC))). Optimisation du param√®tre <code>kernel</code> : ['linear','rbf']\n",
    "* LogisticRegression ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression)). Optimisation du param√®tre <code>C</code> : [0.5,0.75,1]\n",
    "* MultinomialNB ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB)). Pas d'optimisation de param√®tre. \n",
    "* RandomForestClassifier ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforestclassifier#sklearn.ensemble.RandomForestClassifier)). Optimisation du param√®tre <code>max_depth</code> :[5,10,15]\n",
    "* RidgeClassifier ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html?highlight=ridgeclassifier#sklearn.linear_model.RidgeClassifier)) Optimisation du param√®tre <code>alpha</code> : [0.5,0.75,1]\n",
    "\n",
    "**Attention** Certains de ces classifieurs utilisent de l'al√©atoire. Il est donc n√©cessaire de fixer les graines √† l'aide du param√®tre <code>random_state</code>\n",
    "\n",
    "1. Nous allons utiliser un Pipeline dans lequel nous allons ajouter les dictionnaires contenant les classifieurs et leurs param√®tres √† ajuster. Pour cela vous allez vous pouvez vous inspirer du code suivant : \n",
    "```python\n",
    "#Cr√©√© un Pipeline pseudo vide (workaround pour pouvoir utiliser le pipeline avec plusieurs classifieurs)\n",
    "pipeline = Pipeline([\n",
    "    ('clf', UnClassifieur()),\n",
    "    ])\n",
    "\n",
    "#liste des dictionnaires des diff√©rents classifieurs et leurs param√®tres √† tester\n",
    "parameters = [\n",
    "        {\n",
    "            'clf': [UnClassifieur(random_state=0)],\n",
    "            'clf__myParamClassifieur': ['linear','rbf']\n",
    "        }\n",
    "]\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "```\n",
    "Dans le code plus haut le Pipeline est initialis√© avec un classifieur. C'est un workaround car on ne peut pas cr√©er de Pipeline vide. \n",
    "Nous allons utiliser ce Pipeline avec une liste (variable <code>parameters</code>) de dictionnaires contenant le classifieur √† tester et ses param√®tres. \n",
    "Dans le dictionnaire pr√©sent√© plus haut :\n",
    "* <code>'clf'</code> est une liste contenant 1 seul √©l√©ment, le classifieur √† tester.\n",
    "* <code>'clf__myParamClassifieur'</code> permet √† l'algorithme de tester le param√®tres <myParamClassifieur> du classifieur test√© <code>'clf'</code> \n",
    "\n",
    "Pour ajouter les classifieur √† tester vous allez vous baser sur le meme principe, √† savoir, rajouter des dictionnaires dans <code>parameters</code> avec \n",
    "<code>{'clf' : [mon_classif], 'clf__myPara' : [liste_param_√†_tester]}</code>. Vous prendrez la liste des classifieurs/param√®tres donn√©e plus haut dans ce bloc. \n",
    "\n",
    "2. Vous devrez ensuite cr√©er un objet GridSearchCV ([documentation]()) avec en param√®tres : <code>pipeline</code>, <code>parameters</code> et <code>n_jobs=-1</code> (pour obtenir un multi-threading sur l'ensemble des coeurs CPU disponibles).\n",
    "3. Vous utiliserez ensuite la m√©thode fit(X_train,y_train) sur l'objet GridSearch pour lancer la recherche du meilleur couple classifieurs/param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des param√®tres du pipeline pour la GridSearch\n",
    "PIPELINE_PARAMS = [\n",
    "  {\n",
    "    'clf': [SVC(random_state=0)],\n",
    "    'clf__kernel': ['linear', 'rbf']\n",
    "  },\n",
    "  {\n",
    "    'clf': [LogisticRegression(random_state=0)], \n",
    "    'clf__C': [0.5,0.75,1]\n",
    "  },\n",
    "  {\n",
    "    'clf': [MultinomialNB()]\n",
    "  },\n",
    "  {\n",
    "    'clf': [RandomForestClassifier(random_state=0)], \n",
    "    'clf__max_depth' :[5,10,15]\n",
    "  },\n",
    "  {\n",
    "    'clf': [RidgeClassifier(random_state=0)],\n",
    "    'clf__alpha': [0.5,0.75,1]\n",
    "  }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_classifiers(X,binarized_labels):\n",
    "    #S√©paration du jeu de donn√©es en 2. Une partie pour l'entrainement (X_train, y_train) et une partie pour l'√©valuation (X_test, y_test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    print(\"--- Start grid-search ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Placer ici le code avec le pipeline pour le Grid-Search\n",
    "    pipeline = Pipeline([('clf', SVC())])\n",
    "    grid_search = GridSearchCV(pipeline, PIPELINE_PARAMS, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(best_params)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid_search.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"--- %s seconds for grid-search ---\" % (time.time() - start_time))\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc principal d'ex√©cution du Grid Search\n",
    "1. Chargement du jeu de donn√©es de Herzig et al. avec la m√©thode <code>load_dataset(\"dataset_herzig_etal.json\")</code>\n",
    "2. Multiplication du titre des tickets du dataset par un facteur 3 via la m√©thode <code>multiply_title</code>\n",
    "3. Extraction du corpus et des labels via la m√©thode <code>get_corpus_labels</code>\n",
    "3. Vectorisation √† l'aide de TF-IDF. Pour cela, cr√©ez un objet Vectorizer √† l'aide de <code>TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})</code>\n",
    "4. S√©lection des features repr√©sentatives gr√¢ce √† la m√©thode <code>feature_computing</code>\n",
    "5. Recherche d'un classifieur via la m√©thode <code>grid_search_classifiers</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "--- 3.1220407485961914 seconds for feature computing ---\n",
      "--- Start grid-search ---\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf': SVC(random_state=0), 'clf__kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.869 (+/-0.025) for {'clf': SVC(random_state=0), 'clf__kernel': 'linear'}\n",
      "0.879 (+/-0.016) for {'clf': SVC(random_state=0), 'clf__kernel': 'rbf'}\n",
      "0.744 (+/-0.024) for {'clf': LogisticRegression(random_state=0), 'clf__C': 0.5}\n",
      "0.773 (+/-0.019) for {'clf': LogisticRegression(random_state=0), 'clf__C': 0.75}\n",
      "0.796 (+/-0.030) for {'clf': LogisticRegression(random_state=0), 'clf__C': 1}\n",
      "0.732 (+/-0.016) for {'clf': MultinomialNB()}\n",
      "0.681 (+/-0.017) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 5}\n",
      "0.699 (+/-0.017) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 10}\n",
      "0.713 (+/-0.024) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 15}\n",
      "0.875 (+/-0.023) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 0.5}\n",
      "0.870 (+/-0.023) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 0.75}\n",
      "0.863 (+/-0.027) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1225\n",
      "           1       0.88      0.81      0.84       621\n",
      "\n",
      "    accuracy                           0.90      1846\n",
      "   macro avg       0.89      0.88      0.88      1846\n",
      "weighted avg       0.90      0.90      0.90      1846\n",
      "\n",
      "\n",
      "--- 36.111127853393555 seconds for grid-search ---\n"
     ]
    }
   ],
   "source": [
    "#Chargement du jeu de donn√©es JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data, factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des √©tiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des √©tiquettes textuelles en √©tiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Cr√©ation d'un vectorizer \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "\n",
    "#Extraction des features repr√©sentatives du corpus de tickets (ici 55000 features les plus r√©pr√©sentatives)\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer)\n",
    "\n",
    "#Recherche du meilleur classifieur\n",
    "best_params = grid_search_classifiers(X, binarized_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du meilleur classifier\n",
    "\n",
    "On sauvegarde notre meilleur classifier avec les param√®tres obtenus pr√©c√©demment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('clf', SVC(random_state=0))])\n"
     ]
    }
   ],
   "source": [
    "best_clf = Pipeline([('clf', SVC())])\n",
    "best_clf.set_params(**best_params)\n",
    "\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scoring_train_test_split(X,binarized_labels, clf, test_size=33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='f1')\n",
    "    print(\"--- Start training ---\",flush=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"--- %s seconds for training ---\" % (time.time() - start_time),flush=True)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    print(\"F1 score train/test: %0.3f\" % f1)\n",
    "    print(\"Recall score train/test: %0.3f\" % recall)\n",
    "    print(\"Precision score train/test: %0.3f\" % precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âchantillonage pour trouver un nombre de features optimal\n",
    "\n",
    "Nous allons maintenant √©chantillonner le nombre de feature afin de trouver un nombre qui permet de donner de bons r√©sultats.  \n",
    "Pour cela nous allons faire varier le nombre de features entre 20000 et 90000.\n",
    "\n",
    "1. Chargement du jeu de donn√©es de Herzig et al. avec la m√©thode <code>load_dataset(\"dataset_herzig_etal.json\")</code>\n",
    "2. Multiplication du titre des tickets du dataset par un facteur 3 via la m√©thode <code>multiply_title</code>\n",
    "3. Extraction du corpus et des labels via la m√©thode <code>get_corpus_labels</code>\n",
    "4. Vectorisation √† l'aide de TF-IDF. Pour cela, cr√©ez un objet Vectorizer √† l'aide de <code>TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})</code>\n",
    "5. Cr√©ation du classifieur, s√©lectionner le meilleur couple classifieur/param√®tres retourn√© par Grid-Search pr√©c√©demment\n",
    "6.√âchantillonage du nombre de features par pas de 5000 entre 30000 et 60000, dans la boucle faire :\n",
    "* calcul des features √† l'aide de <code>feature_computing</code>\n",
    "* le scoring √† l'aide de la m√©thode <code>make_scoring_train_test_split</code>\n",
    "\n",
    "En cas d'√©galit√© des scores F1 entre diff√©rents nombre de features, vous conserverez la valeur du plus grand nombre de features parmi les meilleurs scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "--- 3.083604335784912 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 15.938332319259644 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 35000 best features by a chi-squared test\n",
      "--- 2.948834180831909 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 17.936676502227783 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 40000 best features by a chi-squared test\n",
      "--- 3.1075525283813477 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 18.096181631088257 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 45000 best features by a chi-squared test\n",
      "--- 3.2231526374816895 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 19.113173961639404 seconds for training ---\n",
      "F1 score train/test: 0.889\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.857\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 50000 best features by a chi-squared test\n",
      "--- 2.796107530593872 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 20.428774118423462 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 55000 best features by a chi-squared test\n",
      "--- 3.1211276054382324 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 21.106807470321655 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 3.1957144737243652 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 22.107197046279907 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Chargement du jeu de donn√©es JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data, factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des √©tiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des √©tiquettes textuelles en √©tiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Cr√©ation d'un vectorizer \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "\n",
    "#Cr√©ation du classifieur\n",
    "classifier = best_clf\n",
    "\n",
    "#Boucle for avec calcul des features et scoring\n",
    "feat_min = 30000\n",
    "feat_max = 60000\n",
    "step = 5000\n",
    "for nb_feat in range (feat_min, feat_max+1, step):\n",
    "    X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer, k_best=nb_feat)\n",
    "    make_scoring_train_test_split(X, binarized_labels, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©ation de la matrice de confusion \n",
    "\n",
    "Nous allons maintenant cr√©er la matrice de confusion correspondant √† notre classifieur. Cette matrice permet de visualiser graphiquement la qualit√© de la classification effectu√©e par notre classifieur. La matrice de confusion recense le nombre de :\n",
    "* vrais positifs (VP)\n",
    "* vrais n√©gatifs (VN)\n",
    "* faux positifs (FP)\n",
    "* faux n√©gatifs (FN)\n",
    "Cette matrice est un indicateur de la qualit√© de votre classifieur. Plus le nombre de FP et FN est r√©duit meilleure est la classification. \n",
    "\n",
    "Pour cr√©er cette matrice il vous faut : \n",
    "1. Comme dans les blocs de code pr√©c√©dent charger le jeu, multiplier le titre, extraire le corpus et les labels puis binariser les labels\n",
    "2. Extraire les <code>k</code> meilleures features en fonction de l'√©chantillonnage fait plus haut (m√©thode <code>feature_computing</code>)\n",
    "3. Utiliser la meilleure configuration de classifieur calcul√©e avec Grid-Search \n",
    "4. Entra√Æner ce classifieur √† l'aide de la m√©thode <code>fit</code> avec <code>X_train</code> et <code>y_train</code>\n",
    "5. Faire des pr√©dictions √† l'aide de la m√©thode <code>predict</code> de votre classifieur\n",
    "\n",
    "Pour cela, vous pouvez vous inspirer de l'exemple donn√© ici : [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 2.872279644012451 seconds for feature computing ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Chargement du jeu de donn√©es JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data, factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des √©tiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des √©tiquettes textuelles en √©tiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Cr√©ation du vectorizer TF-IDF et s√©lection des k-best features avec feature_computin\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer, k_best=60000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "#Cr√©ation du classifieur, entrainement avec X_train, y_train et pr√©diction avec X_test\n",
    "clf = SVC(random_state=0, probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "#affichage de la matrice de confusion ConfusionMatrixDisplay\n",
    "conf = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf, display_labels=clf.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicabilit√© du classifieur\n",
    "\n",
    "Un des d√©fis li√© √† l'IA et aux algorithmes √† trait √† leur explicabilit√©. L'explicabilit√© se d√©finie comme le fait de pouvoir comprendre les m√©canismes internes du classifieur qui fondent une ou plusieurs pr√©dictions. Cette explicabilit√© peut se faire de mani√®re globale (m√©canismes internes du classifieur qui conduisent √† la classification) ou de mani√®re locale (m√©canisme qui conduisent √† la classification d'une instance). \n",
    "\n",
    "Nous allons expliquer la classification de 4 tickets : \n",
    "* 2 tickets sont des faux positifs (indices 3997 et 5098 dans le dataset de tickets)\n",
    "* 2 tickets sont des faux n√©gatifs (indices 2656 et 3479 dans le dataset de tickets)\n",
    "\n",
    "Pour expliquer les mots impactant la classification des tickets nous allons utiliser une m√©thode d'explication se nommant Lime situ√©e dans le package Python [eli5](https://eli5.readthedocs.io/en/latest/index.html). \n",
    "Pour cela vous pouvez vous inspirer de l'exemple donner dans la documentation de eli5 : [https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#textexplainer](https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#textexplainer)\n",
    "\n",
    "**Attention** avant d'ex√©cuter le code suivant, veillez √† avoir ex√©cut√© le code du bloc pr√©c√©dent (code de matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start feature computing ---\n",
      "\t677997 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 5.491630554199219 seconds for feature computing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Documents/M2GL/HAI916I/tp/tp6/Tickets/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>-20.203</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.990\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.213\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\">&quot;</span><span style=\"background-color: hsl(120, 100.00%, 78.09%); opacity: 0.88\" title=\"0.263\">ant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.31%); opacity: 0.89\" title=\"0.276\">test</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 78.75%); opacity: 0.88\" title=\"0.251\">generates</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.40%); opacity: 0.85\" title=\"0.147\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.37%); opacity: 0.82\" title=\"0.069\">following</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.59%); opacity: 0.89\" title=\"0.289\">error</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.09%); opacity: 0.82\" title=\"0.073\">consistently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.08%); opacity: 0.83\" title=\"0.097\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.24%); opacity: 0.88\" title=\"0.260\">run</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.00%); opacity: 0.84\" title=\"0.139\">machine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.89%); opacity: 0.85\" title=\"0.140\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.08%); opacity: 0.83\" title=\"0.097\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.24%); opacity: 0.88\" title=\"0.260\">run</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.244\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.72%); opacity: 0.87\" title=\"0.203\">user</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.20%); opacity: 0.83\" title=\"0.109\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.67%); opacity: 0.86\" title=\"0.173\">administrator</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.31%); opacity: 0.85\" title=\"0.163\">privileges</span><span style=\"opacity: 0.80\">\n",
       "\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(120, 100.00%, 91.20%); opacity: 0.82\" title=\"0.071\">testcase</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(120, 100.00%, 66.65%); opacity: 0.95\" title=\"0.479\">testtmpdirisplainfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 74.19%); opacity: 0.91\" title=\"0.332\">org</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.96%); opacity: 0.84\" title=\"0.112\">apache</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.091\">lucene</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 78.62%); opacity: 0.88\" title=\"0.254\">index</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.112\">store</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">):     caused </span><span style=\"background-color: hsl(120, 100.00%, 83.98%); opacity: 0.85\" title=\"0.168\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.59%); opacity: 0.89\" title=\"0.289\">error</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(120, 100.00%, 68.45%); opacity: 0.94\" title=\"0.442\">access</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.090\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.85%); opacity: 0.83\" title=\"0.100\">denied</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.ioexception: </span><span style=\"background-color: hsl(120, 100.00%, 68.45%); opacity: 0.94\" title=\"0.442\">access</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.090\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.85%); opacity: 0.83\" title=\"0.100\">denied</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 71.00%); opacity: 0.93\" title=\"0.392\">winntfilesystem</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 76.31%); opacity: 0.89\" title=\"0.294\">createfileexclusively</span><span style=\"opacity: 0.80\">(native </span><span style=\"background-color: hsl(120, 100.00%, 84.93%); opacity: 0.85\" title=\"0.154\">method</span><span style=\"opacity: 0.80\">)\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 77.44%); opacity: 0.89\" title=\"0.274\">file</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 83.15%); opacity: 0.86\" title=\"0.181\">createnewfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 77.44%); opacity: 0.89\" title=\"0.274\">file</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.029\">java</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 76.12%); opacity: 0.90\" title=\"0.297\">828</span><span style=\"opacity: 0.80\">)\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.19%); opacity: 0.91\" title=\"0.332\">org</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.96%); opacity: 0.84\" title=\"0.112\">apache</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.091\">lucene</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 78.62%); opacity: 0.88\" title=\"0.254\">index</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.112\">store</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 66.65%); opacity: 0.95\" title=\"0.479\">testtmpdirisplainfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.029\">java</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 87.54%); opacity: 0.84\" title=\"0.117\">66</span><span style=\"opacity: 0.80\">)</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline et vectorizer n√©cessaire pour le TextExplainer\n",
    "vectorizer_for_text_explainer = TfidfVectorizer(min_df=1, max_df=1.0,ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer_for_text_explainer, k_best=60000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "pipe = make_pipeline(vectorizer_for_text_explainer, ch2, clf)\n",
    "\n",
    "#Placez ici le code du text explainer pour le ticket 5098 (ticket_dataset[5098][\"title\"] + ticket_dataset[5098][\"body\"])\n",
    "doc = raw_data[5098][\"title\"] + raw_data[5098][\"body\"]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 3997 (faux positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Documents/M2GL/HAI916I/tp/tp6/Tickets/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>-20.066</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.917\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.148\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.173\">replacing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.070\">an</span><span style=\"opacity: 0.80\"> extended </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.293\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 74.45%); opacity: 0.91\" title=\"0.154\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.73%); opacity: 0.85\" title=\"0.067\">supertype</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.30%); opacity: 0.92\" title=\"0.182\">problematic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.173\">replacing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.070\">an</span><span style=\"opacity: 0.80\"> extended </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.293\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 74.45%); opacity: 0.91\" title=\"0.154\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.73%); opacity: 0.85\" title=\"0.067\">supertype</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.30%); opacity: 0.92\" title=\"0.182\">problematic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.173\">replacing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.070\">an</span><span style=\"opacity: 0.80\"> extended </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.293\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 74.45%); opacity: 0.91\" title=\"0.154\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.73%); opacity: 0.85\" title=\"0.067\">supertype</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.30%); opacity: 0.92\" title=\"0.182\">problematic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.173\">replacing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.070\">an</span><span style=\"opacity: 0.80\"> extended </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.293\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 74.45%); opacity: 0.91\" title=\"0.154\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.73%); opacity: 0.85\" title=\"0.067\">supertype</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> problematicnode.addmixin() / </span><span style=\"background-color: hsl(120, 100.00%, 84.36%); opacity: 0.85\" title=\"0.077\">node</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 66.02%); opacity: 0.96\" title=\"0.232\">removemixin</span><span style=\"opacity: 0.80\">() </span><span style=\"background-color: hsl(120, 100.00%, 72.40%); opacity: 0.92\" title=\"0.172\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.36%); opacity: 0.94\" title=\"0.209\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.64%); opacity: 0.82\" title=\"0.031\">checks</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> avoid </span><span style=\"background-color: hsl(120, 100.00%, 90.17%); opacity: 0.83\" title=\"0.039\">redundant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.38%); opacity: 0.83\" title=\"0.050\">settings</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.10%); opacity: 0.90\" title=\"0.149\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.48%); opacity: 0.83\" title=\"0.049\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.36%); opacity: 0.85\" title=\"0.077\">node</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.66%); opacity: 0.91\" title=\"0.161\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.39%); opacity: 0.91\" title=\"0.164\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.49%); opacity: 0.91\" title=\"0.163\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.06%); opacity: 0.87\" title=\"0.108\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.62%); opacity: 0.94\" title=\"0.207\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.36%); opacity: 0.85\" title=\"0.077\">node</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.88%); opacity: 0.83\" title=\"0.047\">saved</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 82.10%); opacity: 0.86\" title=\"0.093\">eg</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(120, 100.00%, 72.40%); opacity: 0.92\" title=\"0.172\">have</span><span style=\"opacity: 0.80\"> 2 </span><span style=\"background-color: hsl(120, 100.00%, 80.04%); opacity: 0.87\" title=\"0.109\">mixins</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.66%); opacity: 0.91\" title=\"0.161\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.23%); opacity: 0.82\" title=\"0.023\">where</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\"> &gt; </span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.66%); opacity: 0.91\" title=\"0.161\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.48%); opacity: 0.83\" title=\"0.049\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.36%); opacity: 0.85\" title=\"0.077\">node</span><span style=\"opacity: 0.80\"> (n </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.293\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 75.10%); opacity: 0.90\" title=\"0.149\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 67.05%); opacity: 0.95\" title=\"0.222\">then</span><span style=\"opacity: 0.80\">, n.addmixin(</span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\">)  </span><span style=\"background-color: hsl(120, 100.00%, 89.03%); opacity: 0.83\" title=\"0.046\">has</span><span style=\"opacity: 0.80\"> no effect, since </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 74.45%); opacity: 0.91\" title=\"0.154\">s</span><span style=\"opacity: 0.80\"> regarded as </span><span style=\"background-color: hsl(120, 100.00%, 90.17%); opacity: 0.83\" title=\"0.039\">redundant</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 74.35%); opacity: 0.91\" title=\"0.155\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.08%); opacity: 0.93\" title=\"0.193\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.40%); opacity: 0.92\" title=\"0.172\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.53%); opacity: 0.85\" title=\"0.075\">remove</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.11%); opacity: 0.88\" title=\"0.116\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.66%); opacity: 0.91\" title=\"0.161\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.05%); opacity: 0.95\" title=\"0.222\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.42%); opacity: 0.84\" title=\"0.063\">add</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\">.\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 88.35%); opacity: 0.83\" title=\"0.050\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.62%); opacity: 0.94\" title=\"0.207\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.11%); opacity: 0.88\" title=\"0.116\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.32%); opacity: 0.83\" title=\"0.039\">problem</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.06%); opacity: 0.87\" title=\"0.108\">when</span><span style=\"opacity: 0.80\"> applying </span><span style=\"background-color: hsl(120, 100.00%, 77.24%); opacity: 0.89\" title=\"0.131\">mixin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.34%); opacity: 0.86\" title=\"0.084\">types</span><span style=\"opacity: 0.80\"> programmatically, </span><span style=\"background-color: hsl(120, 100.00%, 98.94%); opacity: 0.80\" title=\"0.002\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.70%); opacity: 0.85\" title=\"0.067\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.82%); opacity: 0.81\" title=\"0.008\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.53%); opacity: 0.85\" title=\"0.075\">remove</span><span style=\"opacity: 0.80\"> them </span><span style=\"background-color: hsl(120, 100.00%, 79.11%); opacity: 0.88\" title=\"0.116\">first</span><span style=\"opacity: 0.80\"> before adding new </span><span style=\"background-color: hsl(120, 100.00%, 79.24%); opacity: 0.88\" title=\"0.115\">ones</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 68.62%); opacity: 0.94\" title=\"0.207\">the</span><span style=\"opacity: 0.80\"> 2nd </span><span style=\"background-color: hsl(120, 100.00%, 90.32%); opacity: 0.83\" title=\"0.039\">problem</span><span style=\"opacity: 0.80\"> occurs </span><span style=\"background-color: hsl(120, 100.00%, 80.06%); opacity: 0.87\" title=\"0.108\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.03%); opacity: 0.83\" title=\"0.046\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.48%); opacity: 0.83\" title=\"0.049\">a</span><span style=\"opacity: 0.80\"> mandatory </span><span style=\"background-color: hsl(120, 100.00%, 70.43%); opacity: 0.93\" title=\"0.190\">property</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 67.05%); opacity: 0.95\" title=\"0.222\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.96%); opacity: 0.87\" title=\"0.109\">somehow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.06%); opacity: 0.87\" title=\"0.108\">when</span><span style=\"opacity: 0.80\"> downgrading from </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 68.36%); opacity: 0.94\" title=\"0.209\">some</span><span style=\"opacity: 0.80\"> information </span><span style=\"background-color: hsl(120, 100.00%, 66.55%); opacity: 0.95\" title=\"0.227\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.43%); opacity: 0.85\" title=\"0.069\">lost</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 73.66%); opacity: 0.91\" title=\"0.161\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.48%); opacity: 0.83\" title=\"0.049\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.29%); opacity: 0.91\" title=\"0.156\">save</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.50%); opacity: 0.86\" title=\"0.083\">call</span><span style=\"opacity: 0.80\"> results in\n",
       "\n",
       "unable </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.29%); opacity: 0.91\" title=\"0.156\">save</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.36%); opacity: 0.85\" title=\"0.077\">node</span><span style=\"opacity: 0.80\"> &#x27;n&#x27;: javax.</span><span style=\"background-color: hsl(120, 100.00%, 88.09%); opacity: 0.84\" title=\"0.052\">jcr</span><span style=\"opacity: 0.80\">.nodetype.constraintviolationexception: /test/</span><span style=\"background-color: hsl(120, 100.00%, 88.48%); opacity: 0.83\" title=\"0.049\">a</span><span style=\"opacity: 0.80\">: mandatory </span><span style=\"background-color: hsl(120, 100.00%, 70.43%); opacity: 0.93\" title=\"0.190\">property</span><span style=\"opacity: 0.80\"> {}prop </span><span style=\"background-color: hsl(120, 100.00%, 82.70%); opacity: 0.86\" title=\"0.088\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.39%); opacity: 0.91\" title=\"0.164\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.12%); opacity: 0.84\" title=\"0.058\">exist</span><span style=\"opacity: 0.80\">.\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 70.08%); opacity: 0.93\" title=\"0.193\">you</span><span style=\"opacity: 0.80\"> need </span><span style=\"background-color: hsl(120, 100.00%, 60.85%); opacity: 0.99\" title=\"0.284\">to</span><span style=\"opacity: 0.80\"> &quot;touch&quot; </span><span style=\"background-color: hsl(120, 100.00%, 68.62%); opacity: 0.94\" title=\"0.207\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.43%); opacity: 0.93\" title=\"0.190\">property</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 84.62%); opacity: 0.85\" title=\"0.075\">otherwise</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.76%); opacity: 0.91\" title=\"0.160\">it</span><span style=\"opacity: 0.80\"> will </span><span style=\"background-color: hsl(120, 100.00%, 73.39%); opacity: 0.91\" title=\"0.164\">not</span><span style=\"opacity: 0.80\"> work.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 74.35%); opacity: 0.91\" title=\"0.155\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.49%); opacity: 0.91\" title=\"0.163\">only</span><span style=\"opacity: 0.80\"> this works:\n",
       "\n",
       "n.</span><span style=\"background-color: hsl(120, 100.00%, 66.02%); opacity: 0.96\" title=\"0.232\">removemixin</span><span style=\"opacity: 0.80\">(&quot;</span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.033\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 62.41%); opacity: 0.98\" title=\"0.268\">aa</span><span style=\"opacity: 0.80\">&quot;);\n",
       "n.addmixin(&quot;</span><span style=\"background-color: hsl(0, 100.00%, 73.83%); opacity: 0.91\" title=\"-0.160\">mix</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.81\" title=\"0.022\">a</span><span style=\"opacity: 0.80\">&quot;);\n",
       "n.</span><span style=\"background-color: hsl(120, 100.00%, 92.48%); opacity: 0.82\" title=\"0.027\">setproperty</span><span style=\"opacity: 0.80\">(&quot;prop&quot;, n.getproperty(&quot;prop&quot;).getvalue());\n",
       "session.</span><span style=\"background-color: hsl(120, 100.00%, 74.29%); opacity: 0.91\" title=\"0.156\">save</span><span style=\"opacity: 0.80\">();\n",
       "\n",
       "\n",
       "\n",
       "</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = raw_data[3997][\"title\"] + raw_data[3997][\"body\"]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 2656 (faux n√©gatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Documents/M2GL/HAI916I/tp/tp6/Tickets/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>-9.555</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.246\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.309\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 82.33%); opacity: 0.86\" title=\"-0.195\">thai</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.204\">token</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.96%); opacity: 0.96\" title=\"-0.498\">type</span><span style=\"opacity: 0.80\">() </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.628\">bug</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.79%); opacity: 0.94\" title=\"-0.440\">thai</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.204\">token</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.96%); opacity: 0.96\" title=\"-0.498\">type</span><span style=\"opacity: 0.80\">() </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.628\">bug</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.79%); opacity: 0.94\" title=\"-0.440\">thai</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.204\">token</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.96%); opacity: 0.96\" title=\"-0.498\">type</span><span style=\"opacity: 0.80\">() </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.628\">bug</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.79%); opacity: 0.94\" title=\"-0.440\">thai</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.204\">token</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.39%); opacity: 0.86\" title=\"0.179\">type</span><span style=\"opacity: 0.80\">() </span><span style=\"background-color: hsl(120, 100.00%, 87.14%); opacity: 0.84\" title=\"0.124\">bugwhile</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.02%); opacity: 0.84\" title=\"0.112\">adding</span><span style=\"opacity: 0.80\"> tests </span><span style=\"background-color: hsl(0, 100.00%, 92.70%); opacity: 0.82\" title=\"-0.055\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.60%); opacity: 0.81\" title=\"-0.027\">offsets</span><span style=\"opacity: 0.80\"> &amp; </span><span style=\"background-color: hsl(120, 100.00%, 76.81%); opacity: 0.89\" title=\"0.288\">type</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.287\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.68%); opacity: 0.91\" title=\"0.345\">thaianalyzer</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 89.49%); opacity: 0.83\" title=\"0.093\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.92%); opacity: 0.85\" title=\"0.141\">discovered</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.22%); opacity: 0.86\" title=\"0.197\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.41%); opacity: 0.80\" title=\"0.002\">does</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.40%); opacity: 0.82\" title=\"-0.048\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.81%); opacity: 0.89\" title=\"0.288\">type</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.43%); opacity: 0.95\" title=\"0.468\">thai</span><span style=\"opacity: 0.80\"> numeric </span><span style=\"background-color: hsl(120, 100.00%, 86.56%); opacity: 0.84\" title=\"0.132\">digits</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.029\">correctly</span><span style=\"opacity: 0.80\">.\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 73.68%); opacity: 0.91\" title=\"0.345\">thaianalyzer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.73%); opacity: 0.84\" title=\"0.130\">uses</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.15%); opacity: 0.86\" title=\"0.198\">standardtokenizer</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 77.74%); opacity: 0.89\" title=\"0.272\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.53%); opacity: 0.87\" title=\"0.224\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.21%); opacity: 0.85\" title=\"0.166\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.10%); opacity: 0.81\" title=\"0.023\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.51%); opacity: 0.85\" title=\"-0.147\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.29%); opacity: 0.86\" title=\"-0.180\">issue</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.41%); opacity: 0.83\" title=\"-0.094\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.66%); opacity: 0.87\" title=\"0.222\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.80%); opacity: 0.82\" title=\"0.054\">grammar</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 89.86%); opacity: 0.83\" title=\"-0.088\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.36%); opacity: 0.82\" title=\"0.059\">adds</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.72%); opacity: 0.92\" title=\"0.363\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.150\">entire</span><span style=\"opacity: 0.80\"> [:</span><span style=\"background-color: hsl(120, 100.00%, 67.43%); opacity: 0.95\" title=\"0.468\">thai</span><span style=\"opacity: 0.80\">:] </span><span style=\"background-color: hsl(120, 100.00%, 79.20%); opacity: 0.88\" title=\"0.247\">block</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.287\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.84%); opacity: 0.84\" title=\"0.115\">alphanum</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.74%); opacity: 0.81\" title=\"-0.035\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.90%); opacity: 0.84\" title=\"0.114\">propose</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 79.46%); opacity: 0.88\" title=\"0.242\">alphanum</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.089\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.86%); opacity: 0.81\" title=\"-0.017\">described</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.56%); opacity: 0.88\" title=\"-0.241\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.22%); opacity: 0.84\" title=\"-0.137\">little</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.59%); opacity: 0.81\" title=\"0.046\">bit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.57%); opacity: 0.86\" title=\"0.176\">differently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.76%); opacity: 0.83\" title=\"0.090\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.18%); opacity: 0.84\" title=\"0.110\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.17%); opacity: 0.86\" title=\"0.198\">grammar</span><span style=\"opacity: 0.80\">.\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 83.34%); opacity: 0.86\" title=\"0.180\">instead</span><span style=\"opacity: 0.80\">, [:</span><span style=\"background-color: hsl(120, 100.00%, 88.15%); opacity: 0.84\" title=\"0.110\">letter</span><span style=\"opacity: 0.80\">:] </span><span style=\"background-color: hsl(0, 100.00%, 85.14%); opacity: 0.85\" title=\"-0.153\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.064\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.86%); opacity: 0.83\" title=\"-0.101\">allowed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.287\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.42%); opacity: 0.83\" title=\"0.082\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.76%); opacity: 0.83\" title=\"0.090\">diacritics</span><span style=\"opacity: 0.80\">/signs/</span><span style=\"background-color: hsl(0, 100.00%, 81.79%); opacity: 0.86\" title=\"-0.204\">combining</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.58%); opacity: 0.86\" title=\"-0.191\">marks</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.106\">attached</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.287\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.22%); opacity: 0.86\" title=\"0.197\">it</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 80.53%); opacity: 0.87\" title=\"0.224\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.02%); opacity: 0.84\" title=\"-0.112\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.10%); opacity: 0.81\" title=\"-0.023\">allow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.96%); opacity: 0.87\" title=\"0.217\">the</span><span style=\"opacity: 0.80\"> [:</span><span style=\"background-color: hsl(120, 100.00%, 67.43%); opacity: 0.95\" title=\"0.468\">thai</span><span style=\"opacity: 0.80\">:] </span><span style=\"background-color: hsl(0, 100.00%, 87.92%); opacity: 0.84\" title=\"-0.113\">hack</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.84%); opacity: 0.81\" title=\"0.043\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.93%); opacity: 0.83\" title=\"0.088\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.30%); opacity: 0.84\" title=\"0.136\">completely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.16%); opacity: 0.82\" title=\"0.073\">removed</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 88.02%); opacity: 0.84\" title=\"-0.112\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.60%); opacity: 0.83\" title=\"0.104\">allow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.35%); opacity: 0.86\" title=\"0.179\">standardtokenizer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.287\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.84%); opacity: 0.82\" title=\"0.054\">parse</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.82%); opacity: 0.83\" title=\"0.102\">complex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.90%); opacity: 0.82\" title=\"0.076\">writing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.97%); opacity: 0.87\" title=\"0.217\">systems</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.90%); opacity: 0.83\" title=\"-0.101\">such</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.043\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.27%); opacity: 0.83\" title=\"0.083\">indian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.75%); opacity: 0.86\" title=\"0.173\">languages</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 79.13%); opacity: 0.88\" title=\"0.248\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.70%); opacity: 0.84\" title=\"0.116\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.43%); opacity: 0.86\" title=\"0.178\">fix</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.26%); opacity: 0.80\" title=\"0.002\">lucene</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 84.25%); opacity: 0.85\" title=\"0.166\">1545</span><span style=\"opacity: 0.80\">.\n",
       "</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = raw_data[2656][\"title\"] + raw_data[2656][\"body\"]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 3479 (faux n√©gatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/Documents/M2GL/HAI916I/tp/tp6/Tickets/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.972</b>, score <b>-3.547</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.305\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.243\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 90.78%); opacity: 0.82\" title=\"-0.071\">group</span><span style=\"opacity: 0.80\">#</span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.023\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.40%); opacity: 0.87\" title=\"-0.209\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.13%); opacity: 0.93\" title=\"-0.381\">list</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.186\">inherited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.578\">members</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.94%); opacity: 0.87\" title=\"-0.200\">multiple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.91%); opacity: 0.86\" title=\"-0.172\">times</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.31%); opacity: 0.87\" title=\"-0.195\">group</span><span style=\"opacity: 0.80\">#</span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.023\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.40%); opacity: 0.87\" title=\"-0.209\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.13%); opacity: 0.93\" title=\"-0.381\">list</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.186\">inherited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.578\">members</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.94%); opacity: 0.87\" title=\"-0.200\">multiple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.91%); opacity: 0.86\" title=\"-0.172\">times</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.31%); opacity: 0.87\" title=\"-0.195\">group</span><span style=\"opacity: 0.80\">#</span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.023\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.40%); opacity: 0.87\" title=\"-0.209\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.13%); opacity: 0.93\" title=\"-0.381\">list</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.186\">inherited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.578\">members</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.94%); opacity: 0.87\" title=\"-0.200\">multiple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.91%); opacity: 0.86\" title=\"-0.172\">times</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.31%); opacity: 0.87\" title=\"-0.195\">group</span><span style=\"opacity: 0.80\">#</span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.023\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.40%); opacity: 0.87\" title=\"-0.209\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.13%); opacity: 0.93\" title=\"-0.381\">list</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.186\">inherited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.578\">members</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.97%); opacity: 0.84\" title=\"0.116\">multiple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.098\">timesi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.91%); opacity: 0.83\" title=\"0.081\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.22%); opacity: 0.84\" title=\"0.113\">happen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.38%); opacity: 0.87\" title=\"0.194\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.98%); opacity: 0.91\" title=\"0.330\">detect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.57%); opacity: 0.87\" title=\"0.206\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.14%); opacity: 0.83\" title=\"-0.090\">following</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.57%); opacity: 0.83\" title=\"-0.073\">regression</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.17%); opacity: 0.85\" title=\"0.140\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.14%); opacity: 0.84\" title=\"-0.127\">seems</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.76%); opacity: 0.82\" title=\"-0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.98%); opacity: 0.82\" title=\"0.058\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.32%); opacity: 0.91\" title=\"0.307\">introduces</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.78%); opacity: 0.85\" title=\"-0.132\">quite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.57%); opacity: 0.83\" title=\"-0.073\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.059\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.96%); opacity: 0.81\" title=\"0.039\">ago</span><span style=\"opacity: 0.80\">:\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 90.78%); opacity: 0.82\" title=\"-0.071\">group</span><span style=\"opacity: 0.80\">#</span><span style=\"background-color: hsl(120, 100.00%, 76.96%); opacity: 0.89\" title=\"0.263\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.75%); opacity: 0.86\" title=\"0.174\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.06%); opacity: 0.85\" title=\"0.141\">defined</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.38%); opacity: 0.87\" title=\"0.194\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.57%); opacity: 0.83\" title=\"0.085\">return</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.22%); opacity: 0.83\" title=\"0.089\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.78%); opacity: 0.82\" title=\"0.071\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.10%); opacity: 0.82\" title=\"-0.057\">members</span><span style=\"opacity: 0.80\"> including </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.059\">those</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.19%); opacity: 0.87\" title=\"0.212\">inherited</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.01%); opacity: 0.84\" title=\"0.129\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.31%); opacity: 0.83\" title=\"0.100\">another</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.78%); opacity: 0.82\" title=\"0.071\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.59%); opacity: 0.88\" title=\"0.221\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.85%); opacity: 0.91\" title=\"0.315\">member</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.16%); opacity: 0.83\" title=\"0.090\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.31%); opacity: 0.82\" title=\"0.045\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.024\">group</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 91.93%); opacity: 0.82\" title=\"0.059\">example</span><span style=\"opacity: 0.80\">:\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 81.04%); opacity: 0.87\" title=\"0.199\">user</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.91%); opacity: 0.85\" title=\"0.130\">t</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 90.78%); opacity: 0.82\" title=\"0.071\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.059\">a</span><span style=\"opacity: 0.80\"> : </span><span style=\"background-color: hsl(0, 100.00%, 88.34%); opacity: 0.83\" title=\"-0.099\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.097\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.54%); opacity: 0.80\" title=\"0.011\">declared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.43%); opacity: 0.83\" title=\"0.098\">member</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 86.78%); opacity: 0.84\" title=\"-0.119\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.50%); opacity: 0.85\" title=\"-0.149\">b</span><span style=\"opacity: 0.80\"> : </span><span style=\"background-color: hsl(0, 100.00%, 76.47%); opacity: 0.89\" title=\"-0.271\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.097\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.54%); opacity: 0.80\" title=\"0.011\">declared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.43%); opacity: 0.83\" title=\"0.098\">member</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.12%); opacity: 0.81\" title=\"-0.037\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.83%); opacity: 0.81\" title=\"-0.031\">c</span><span style=\"opacity: 0.80\"> : </span><span style=\"background-color: hsl(0, 100.00%, 88.81%); opacity: 0.83\" title=\"-0.094\">a</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.49%); opacity: 0.81\" title=\"0.043\">b</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.24%); opacity: 0.91\" title=\"0.308\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.54%); opacity: 0.80\" title=\"0.011\">declared</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.10%); opacity: 0.82\" title=\"-0.057\">members</span><span style=\"opacity: 0.80\">\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 80.57%); opacity: 0.87\" title=\"0.206\">the</span><span style=\"opacity: 0.80\"> expected result </span><span style=\"background-color: hsl(120, 100.00%, 89.16%); opacity: 0.83\" title=\"0.090\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.78%); opacity: 0.82\" title=\"-0.071\">group</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 76.96%); opacity: 0.89\" title=\"0.263\">getmembers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.97%); opacity: 0.82\" title=\"0.048\">was</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(0, 100.00%, 91.56%); opacity: 0.82\" title=\"-0.063\">a</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.49%); opacity: 0.81\" title=\"0.043\">b</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 98.42%); opacity: 0.80\" title=\"0.006\">t</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 76.26%); opacity: 0.89\" title=\"-0.274\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.54%); opacity: 0.85\" title=\"-0.135\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.78%); opacity: 0.86\" title=\"-0.159\">currently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.49%); opacity: 0.81\" title=\"0.026\">happening</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.51%); opacity: 0.83\" title=\"0.085\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.62%); opacity: 0.82\" title=\"0.052\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.34%); opacity: 0.83\" title=\"-0.099\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.20%); opacity: 0.85\" title=\"0.140\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.22%); opacity: 0.88\" title=\"0.243\">included</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.47%); opacity: 0.84\" title=\"-0.123\">twice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.21%); opacity: 0.88\" title=\"-0.227\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.63%); opacity: 0.87\" title=\"-0.190\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.45%); opacity: 0.92\" title=\"-0.339\">returned</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.69%); opacity: 0.81\" title=\"0.041\">iterator</span><span style=\"opacity: 0.80\">.\n",
       "quickly </span><span style=\"background-color: hsl(0, 100.00%, 95.30%); opacity: 0.81\" title=\"-0.027\">testing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.30%); opacity: 0.81\" title=\"-0.027\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.91%); opacity: 0.84\" title=\"0.117\">jackrabbit</span><span style=\"opacity: 0.80\"> 2.</span><span style=\"background-color: hsl(0, 100.00%, 75.63%); opacity: 0.90\" title=\"-0.285\">0</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.63%); opacity: 0.90\" title=\"-0.285\">revealed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.17%); opacity: 0.85\" title=\"0.140\">that</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(120, 100.00%, 99.51%); opacity: 0.80\" title=\"0.001\">used</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.38%); opacity: 0.87\" title=\"0.194\">to</span><span style=\"opacity: 0.80\"> work before...\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 88.58%); opacity: 0.83\" title=\"0.096\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.97%); opacity: 0.90\" title=\"0.279\">didn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 85.91%); opacity: 0.85\" title=\"0.130\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.72%); opacity: 0.83\" title=\"0.095\">carefully</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.51%); opacity: 0.84\" title=\"0.110\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.015\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.14%); opacity: 0.81\" title=\"0.028\">that</span><span style=\"opacity: 0.80\"> bug </span><span style=\"background-color: hsl(0, 100.00%, 85.22%); opacity: 0.85\" title=\"-0.139\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.22%); opacity: 0.85\" title=\"-0.139\">been</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.01%); opacity: 0.86\" title=\"0.185\">introduced</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.77%); opacity: 0.83\" title=\"0.094\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.57%); opacity: 0.87\" title=\"0.206\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.86%); opacity: 0.81\" title=\"0.023\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.87%); opacity: 0.86\" title=\"-0.187\">refactoring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.59%); opacity: 0.81\" title=\"0.033\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.57%); opacity: 0.87\" title=\"0.206\">the</span><span style=\"opacity: 0.80\"> membership\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 74.73%); opacity: 0.90\" title=\"0.300\">collections</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.14%); opacity: 0.84\" title=\"-0.127\">seems</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.76%); opacity: 0.82\" title=\"-0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.98%); opacity: 0.82\" title=\"0.058\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.059\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.15%); opacity: 0.85\" title=\"0.154\">possible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.65%); opacity: 0.82\" title=\"0.062\">culprit</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = raw_data[3479][\"title\"] + raw_data[3479][\"body\"]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604fa18f26e0fae5824a25e5208a65f3bd7a50a3ed33678f9d75b9937a80ef56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
